{
  "hash": "5687e3733d4001ab85159f937057bab8",
  "result": {
    "markdown": "---\ntitle: \"Dimensionality reduction with Uniform Manifold Approximation and Projection\"\ndate: \"2023-02-07\"\ncategories: [dimensionality reduction, UMAP, PCA]\ndescription: 'Using UMAP with R'\ndraft: false\n---\n\n\nUniform Manifold Approximation and Projection, [UMAP](https://arxiv.org/abs/1802.03426) for short, is a method which can be used to reduce the number of dimensions in a data set. Dimensionality reduction methods can be very useful when you are dealing with a large number of features, and can help mitigate issues such as multicollinearity. Personally I like to use them during exploratory data analysis. The [umap](https://cran.r-project.org/web/packages/umap/vignettes/umap.html) package provides means for using UMAP with R. Let's explore the use of UMAP a bit and compare it to another dimensionality reduction technique, Principal Component Analysis (PCA).\n\n## Using the built-in data `swiss`\n\nLet's test drive both UMAP and PCA by using the built-in `swiss` data, which contains different numeric indicators for 47 Swiss municipalities.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\ntheme_set(theme_minimal())\n\n# load the built-in data\ndata(swiss)\n\nglimpse(swiss)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 47\nColumns: 6\n$ Fertility        <dbl> 80.2, 83.1, 92.5, 85.8, 76.9, 76.1, 83.8, 92.4, 82.4,…\n$ Agriculture      <dbl> 17.0, 45.1, 39.7, 36.5, 43.5, 35.3, 70.2, 67.8, 53.3,…\n$ Examination      <int> 15, 6, 5, 12, 17, 9, 16, 14, 12, 16, 14, 21, 14, 19, …\n$ Education        <int> 12, 9, 5, 7, 15, 7, 7, 8, 7, 13, 6, 12, 7, 12, 5, 2, …\n$ Catholic         <dbl> 9.96, 84.84, 93.40, 33.77, 5.16, 90.57, 92.85, 97.16,…\n$ Infant.Mortality <dbl> 22.2, 22.2, 20.2, 20.3, 20.6, 26.6, 23.6, 24.9, 21.0,…\n```\n:::\n:::\n\n\nWe can condense the variability found in the data into smaller dimensions by using PCA. Let's see how.\n\n## Dimensionality reduction via PCA\n\nThere are many packages for performing PCA in R. For example, the {stats} package has the `prcomp` function. Let's use it, and visualize the first two principal components.\n \n\n::: {.cell}\n\n```{.r .cell-code}\n# Perform PCA\npca.out <- prcomp(swiss, scale. = TRUE)\n\n# record names of municipalities into a tibble\nmunicipalities <- row.names(pca.out$x) %>% \n  as_tibble() %>% \n  rename(municipality = value)\n\n# visualize first two principal components\npca.out$x %>% \n  as_tibble() %>% \n  bind_cols(municipalities) %>% \n  ggplot(aes(x = PC1, y = PC2, label = municipality)) +\n  geom_point() +\n  geom_text(check_overlap = TRUE, nudge_y = -0.1) +\n  ggtitle(\"PCA output\")\n```\n\n::: {.cell-output-display}\n![The first two principal components of the `swiss` data.](04-umap_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nFrom the plot above we can see which municipalities share similarities based on the data. That being said, this example is somewhat artificial, and does not make much sense beyond testing PCA output. In a more pragmatic setting, we might be interested, for example, if some numeric features help us to classify the observations into different classes. Here, we might want to know if the other numeric indicators in the data are connected to e.g. `Fertility`.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![A histogram of fertility values in the swiss data.](04-umap_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nLet's define `70` as the limit of high fertility and label municipalities above this threshold as `High`. This choice divides the observations into two approximately equal sized groups, but other than that is completely arbitrary. Let's re-try PCA with the remaining numeric columns.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# modified data with fertility classes\nswiss_mod <- swiss %>% \n  mutate(fert_class = if_else(Fertility > 70, true = \"High\", false = \"Low\")) %>% \n  select(-Fertility)\n\n# PCA without the Fertility column\npca_mod <- prcomp(select(swiss_mod, -fert_class), scale. = TRUE)\n\n# visualize first two principal components for the modified data\npca_mod$x %>% \n  as_tibble() %>% \n  bind_cols(municipalities) %>% \n  bind_cols(select(swiss_mod, fert_class)) %>% \n  ggplot(aes(x = PC1, y = PC2, label = municipality, color = fert_class)) +\n  geom_point() +\n  geom_text(check_overlap = TRUE, nudge_y = -0.1) +\n  ggtitle(\"PCA output\", subtitle = \"Fertility divided into two classes\") +\n  scale_color_manual(values = brewer.pal(n = 3, \"Pastel1\")) +\n  labs(color = \"Fertility:\")\n```\n\n::: {.cell-output-display}\n![The first two principal components of the modified `swiss` data. Municipalities are marked as having High fertility if the numeric value exceeds 70.](04-umap_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nWe can see that the numeric columns provide some degree of separation between the high and low fertility municipalities.\n\n## Dimensionality reduction with UMAP\n\nLet's try the `umap` function on the modified `swiss` data to see what we get as output.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(umap)\nset.seed(123)\n\n# calculate UMAP for the data\numap.out <- umap(select(swiss_mod, -fert_class))\n\n# plot the two UMAP components\numap.out$layout %>% \n  as.data.frame() %>% \n  rename(UMAP1 = V1, UMAP2 = V2) %>% \n  bind_cols(municipalities) %>% \n  bind_cols(select(swiss_mod, fert_class)) %>% \n  ggplot(aes(x = UMAP1, y = UMAP2, label = municipality, color = fert_class)) +\n  geom_point() +\n  geom_text(check_overlap = TRUE, nudge_y = -0.1) +\n  ggtitle(\"UMAP output\") +\n  scale_color_manual(values = brewer.pal(n = 3, \"Pastel1\"))  +\n  labs(color = \"Fertility:\")\n```\n\n::: {.cell-output-display}\n![The first two UMAP components for the modified `swiss` data.](04-umap_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nWe can see that the output from UMAP is somewhat different. The observations are more clearly divided into two clusters. The clusters do not seem to fully overlap with the Fertility classes we constructed.\n\nIt is good to understand that the UMAP algorithm contains a random element, which means that the output of the algorithm differs slightly depending on the random seed. Let's test this by running the calculations again with a different seed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(345)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Re-calculated UMAP components with a different random seed.](04-umap_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nWe notice that the output is quite similar, but still slightly different. There are actually quite a few arguments we can feed to the `umap` function. The default values are listed under `umap.defaults`. Let's take a look.\n\n\n::: {.cell}\n\n```{.r .cell-code}\numap.defaults\n```\n\n::: {.cell-output .cell-output-stderr}\n```\numap configuration parameters\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n           n_neighbors: 15\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n          n_components: 2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n                metric: euclidean\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n              n_epochs: 200\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n                 input: data\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n                  init: spectral\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n              min_dist: 0.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n      set_op_mix_ratio: 1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n    local_connectivity: 1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n             bandwidth: 1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n                 alpha: 1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n                 gamma: 1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n  negative_sample_rate: 5\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n                     a: NA\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n                     b: NA\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n                spread: 1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n          random_state: NA\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n       transform_state: NA\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n                   knn: NA\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n           knn_repeats: 1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n               verbose: FALSE\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n       umap_learn_args: NA\n```\n:::\n:::\n\n\nBy changing these default values we can affect the output. Let's see what happens when we change the default number of components and nearest neighbors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# re-calculate UMAP for the data\numap.out <- umap(select(swiss_mod, -fert_class),\n                 n_components = 4, \n                 random_state = 333,\n                 n_neighbors = 5)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Re-calculated first and second UMAP components with a different random seed, more components and smaller number of nearest neighbors.](04-umap_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nNow the output resembles more the one we got by using PCA. The [original article on UMAP](https://arxiv.org/pdf/1802.03426.pdf) goes into finer detail with regards to the effects of hyperparameter tuning, but we can certainly see that we can tune the output significantly. \n\n# Final thoughts\n\nThe {umap} package makes it easy to use UMAP in R. Although we barely scratched the surface here, we were able to see how UMAP gives different outputs compared to PCA.\n\nIf you are interested in using UMAP as a part of your modeling pipeline, you can also find it from [tidymodels](https://www.tmwr.org/dimensionality.html). Julia Silge has a nice [blog post](https://juliasilge.com/blog/cocktail-recipes-umap/) comparing the use of PCA and UMAP in this setting.\n",
    "supporting": [
      "04-umap_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}